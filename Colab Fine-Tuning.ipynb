{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {"id": "intro"},
      "source": [
        "# Colab Fine-Tuning (LoRA)\n",
        "\n",
        "This notebook runs a small LoRA fine-tune with `train_lora_hunyuanvideo.py` using preprocessed data and frames.\n",
        "It expects:\n",
        "- Model checkpoint in `/content/drive/My Drive/HunyuanVideo-diffusers` (or a subfolder with `model_index.json`).\n",
        "- Dataset manifest at `/content/drive/My Drive/data/dataset.jsonl` (from the preprocessing/frames notebook)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "mount"},
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "mount-drive"},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "paths"},
      "source": [
        "## Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "set-paths"},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "MOUNT = Path('/content/drive') / 'My Drive'\n",
        "MODEL_DIR = MOUNT / 'HunyuanVideo-diffusers'\n",
        "DATASET_JSONL = MOUNT / 'data' / 'dataset.jsonl'\n",
        "OUTPUT_DIR = MOUNT / 'outputs' / 'lora'\n",
        "print('Model dir:', MODEL_DIR)\n",
        "print('Dataset:', DATASET_JSONL)\n",
        "print('Output dir:', OUTPUT_DIR)\n",
        "print('Repo root (current dir):', Path('.').resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "install"},
      "source": [
        "## Install dependencies\n",
        "Installs requirements from this repo; you can also pin specific versions if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "pip-install"},
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "python -V\n",
        "pip install -U pip setuptools wheel >/dev/null 2>&1 || true\n",
        "# Install minimal deps if requirements.txt not present\n",
        "if [ -f requirements.txt ]; then\n",
        "  pip install -r requirements.txt\n",
        "else\n",
        "  pip install 'diffusers>=0.30' 'transformers>=4.43' 'accelerate>=0.30' safetensors Pillow\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "checks"},
      "source": [
        "## Sanity checks\n",
        "Verify model folder and dataset manifest exist; show help for the training script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "verify"},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "assert Path('train_lora_hunyuanvideo.py').exists(), 'Run this notebook from the repo root.'\n",
        "print('Model folder exists:', MODEL_DIR.exists())\n",
        "print('Dataset manifest exists:', Path(DATASET_JSONL).exists())\n",
        "!python train_lora_hunyuanvideo.py --help | sed -n '1,60p'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "train"},
      "source": [
        "## Train (LoRA)\n",
        "Small example settings suited for Colab or limited resources. Adjust as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "run-train"},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "args = [\n",
        "  'python','train_lora_hunyuanvideo.py',\n",
        "  '--model_id', str(MODEL_DIR),\n",
        "  '--dataset', str(DATASET_JSONL),\n",
        "  '--output_dir', str(OUTPUT_DIR),\n",
        "  '--resolution','384',\n",
        "  '--num_frames','8',\n",
        "  '--rank','4',\n",
        "  '--alpha','8',\n",
        "  '--lr','1e-4',\n",
        "  '--batch_size','1',\n",
        "  '--max_steps','200',\n",
        "  '--gradient_accumulation','4',\n",
        "]\n",
        "print('Running:', ' '.join(args))\n",
        "subprocess.run(args, check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "artifacts"},
      "source": [
        "## Artifacts\n",
        "List saved LoRA weights and show their path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "list-artifacts"},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "for p in Path(OUTPUT_DIR).glob('**/lora_weights.pt'):\n",
        "    print('Saved:', p)\n",
        "print('Done.')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {"name": "Colab Fine-Tuning", "provenance": []},
    "kernelspec": {"name": "python3", "display_name": "Python 3"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

